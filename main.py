from pyclbr import Class
from networkx.algorithms.centrality import group
from network import Network
from descriptive import Person_links
from group import Group
from node import Node
from itertools import product
import math
import random
import pandas as pd
import networkx as nx
import numpy as np
import multiprocessing as mp
import matplotlib.pyplot as plt
from pathlib import Path


def initialize_nodes(df, G, division):
    '''
    Initilizes all the nodes for the network
    '''

    # Initialize list with nodes and nodes per group (example: Man,"[0,20)",1,Autochtoon)
    all_nodes = []
    group_nodes = {}

    # Loops through all lines in the tab_n file and get group properties of each line
    for i in range(df.shape[0]):
        group = df.iloc[i]

        
        age = group['lft']
        etnc = group['etngrp']
        gender = group['geslacht']
        education = group['oplniv']
        amount = group['n']
        nodes = []

        # Makes n (the size of the group) nodes of the group
        for j in range(math.ceil((group['n'])/division)):
            id = f'{i}_{j}'
            node = Node(id,age, etnc, education ,gender, amount)
            nodes.append(node)
            G.add_node(node.id)
            all_nodes.append(node)

        # make a dictionary with as key the group properties and value a list of nodes of the group
        group_nodes[f'{age}, {etnc}, {gender}, {education}'] = nodes

        

    return all_nodes, group_nodes

def initialize_edges_probability(df_edges, all_nodes, group_nodes, source = None, destination = None):
    '''
    Initializes the edges of a chosen network (household, family etc.), based on probability
    '''

    # Initializes the source and destinations lists
    source = []
    destination = []

    
    # Loops through all nodes (generated by the initialize node function) and makes links
    for count, node in enumerate(all_nodes):
        
        # Get persons based on the nodes poperties
        person = Person_links(df_edges,node.gender, node.age, node.education, node.etnicity)

        # Get the total amount of links the person group has
        group_links = sum(person.links['n'])

        # Divide the groups link by the amout of nodes so every node gets the same amount of links
        links = group_links/node.amount

        # Update
        if count % 100 == 0:
            print(count/len(all_nodes))

        # Make link based on probability
        prob = person.links['fn']/sum(person.links['fn'])
        
        # Get a list with all the destination groups the current group has
        groups = [f'{age}, {etnc}, {gender}, {education}' for age, etnc, gender, education in zip(person.links['lft_dst'],
        person.links['etngrp_dst'], person.links['geslacht_dst'], person.links['oplniv_dst'])]


        
        # Checks if probability is higher than 0
        if sum(prob) == 0:
            continue

        
        # Get a list (of length links) of destination nodes based on the probability of the link
        destination_nodes = np.random.choice(groups, round(links), p=prob)

        # Loop through the destination nodes and make connection
        for person in destination_nodes:
            
            # Take node id as source
            source.append(node.id)

            # Choose random node from the destination group and make destination node
            try : 
                node2 = np.random.choice(group_nodes[person])
            except:
                print(group_nodes[person])
                print(person)

            destination.append(node2.id)
            
        #     # G.add_edge(node.id, node2.id)
    return source, destination

    


def initialize_edges_links(df_edges, all_nodes, layer ,group_nodes, division, id_source = None, id_destination = None, source = None, destination = None, barabasi = False):     
    '''
    Initializes the links based on the links per group instead of the probability
    '''     

    symetric = False

    if layer == 'huishouden' or layer == 'familie':

        symetric = True
        symetry_dict = {}
        src_groups = []
        dst_groups = []

        for row in df_edges.iterrows():

            row = row[1]
            
            dst_group = f"{row['lft_dst']}, {row['etngrp_dst']}, {row['geslacht_dst']}, {row['oplniv_dst']}"
           
            src_group = f"{row['lft_src']}, {row['etngrp_src']}, {row['geslacht_src']}, {row['oplniv_src']}"

            src_groups.append(src_group)
            dst_groups.append(dst_group)

        df = pd.DataFrame({'src_grps': src_groups, 'dst_grps' : dst_groups})


        for combination in list(product(df['src_grps'], df['dst_grps'])):
            symetry_dict[combination] = 0


    # Divide by the division of (notes ^2)/2 if division > 1
    if division > 1 :
        division = (division**2)/4
    
    # Initializes the source and destinations lists if not multiprocessed
    if source == None and destination == None:
        source = []
        destination = []
        id_source = []
        id_destination = []

    
    # Loops through all connections (generated by the initialize node function) and makes links
    for count, row in enumerate(df_edges.iterrows()):
        print(count)
        if count%100 == 0:

            print(count/len(df_edges))
            
        row = row[1]

        # Identifies source and destination group
        src_group = f"{row['lft_src']}, {row['etngrp_src']}, {row['geslacht_src']}, {row['oplniv_src']}"
        dst_group = f"{row['lft_dst']}, {row['etngrp_dst']}, {row['geslacht_dst']}, {row['oplniv_dst']}"
        

        # Divides the number of edges by the diviser
        connections = round(row['n']/division)


        # If te data is symetric (familie, household), initiate a dictionary for the destination group
        if symetric:
            connections = connections - symetry_dict[(dst_group, src_group)]
     
        # If there are no connections between the source group and the destination group we continue
        if connections == 0:
            continue

        # # If Barabasi parameter is used do the following
        if barabasi:

            # Get total edges
            tot_edges = connections

            # Initialize dictionary with the node id as key and initial edges, 1, as value
            nodes_p = zip(
                    group_nodes[dst_group], 
                    [1]*len(group_nodes[dst_group])
                    )

            nodes_p = dict(nodes_p)

        
        for _ in range(connections):
            
            while True:
                
                # Take random source node and destination node based on the groups
                if len(group_nodes[src_group]) > 0 and len(group_nodes[dst_group]):
                    src_node = np.random.choice(group_nodes[src_group])
                    dst_node = np.random.choice(group_nodes[dst_group])
                else:
                    break


                if barabasi and dst_node.id != src_node.id and dst_node not in src_node.links:
                    nodes = list(nodes_p.keys())
                    nodes_weights =(np.asarray(list(nodes_p.values()))**barabasi).flatten()

                    # print(nodes_weights)
                    dst_node = random.choices(list(nodes), list(nodes_weights))[0]

                    nodes_p[dst_node] += 1
                
                # Checks if the source and destination node are not the same and checks if they aren't already linked
                elif dst_node.id != src_node.id and dst_node not in src_node.links:
                    
                    # Checks if data is symetric 
                    if symetric and src_node not in dst_node.links:


                        source.append(str(dst_node))
                        destination.append(str(src_node))
                        src_node.links.append(src_node)
                    
                        id_source.append(dst_node.id)
                        id_destination.append(src_node.id)
                        
                        symetry_dict[(src_group, dst_group)] += 1

                    # Appends both nodes to lists
                    source.append(str(src_node))
                    destination.append(str(dst_node))
                
                    id_source.append(src_node.id)
                    id_destination.append(dst_node.id)

                    src_node.links.append(dst_node)

                        
                    break
            
            
    return source, destination, id_source, id_destination



if __name__ == '__main__':


    '''
    Initialize nodes 
    '''
    G = nx.DiGraph()
    division = 10
    df_nodes = pd.read_csv('Data/tab_n_(with oplniv).csv')
    all_nodes, group_nodes = initialize_nodes(df_nodes, G, division)


    '''
    Initialize edges for multiple layers
    '''

    layers = 'werkschool','buren'

    
    for layer_number, layer in enumerate(layers):
        
    
        df_edges = pd.read_csv(f'Data/tab_{layer}.csv')
        source, destination, source_id, destination_id = initialize_edges_links(df_edges, all_nodes, layer ,group_nodes, division, id_source = None, id_destination = None, source = None, destination = None, barabasi = 1)

        

        # df_edges = pd.read_csv(f'Data/tab_{layer}.csv')
        # df_edges = np.array_split(df_edges, 6)
    
        # manager = mp.Manager()
        # source = manager.list()
        # destination = manager.list()
        # source_id = manager.list()
        # destination_id = manager.list()
        # all_nodes = np.array_split(all_nodes,6)

        
        # processes = []    
        # for i in range(6):
        #     process = mp.Process(target=initialize_edges_links, args=(df_edges[i], all_nodes[i], layer, group_nodes,division,source_id ,destination_id,source, destination))
        #     processes.append(process)

        # for process in processes:
        #     process.start()

        # for process in processes:
        #     process.join()

        d = {'source_id': list(source_id), 'destination_id':list(destination_id), 'source_group': list(source), 'destination_group': list(destination)}

        df_ = pd.DataFrame(d)

        
        df_.to_csv(f'Data/NW_data/{layer}_nw_b2.csv')


    

    


    