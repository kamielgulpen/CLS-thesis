from networkx.algorithms.centrality import group
from network import Network
from descriptive import Person_links
from group import Group
from node import Node

# importing product
from itertools import product
  
import math
import pandas as pd
import networkx as nx
import numpy as np
import multiprocessing as mp
import matplotlib.pyplot as plt

def initialize_nodes(df, G, division):
    '''
    Initilizes all the nodes for the network
    '''

    # Initialize list with nodes and nodes per group (example: Man,"[0,20)",1,Autochtoon)
    all_nodes = []
    group_nodes = {}

    # Loops through all lines in the tab_n file and get group properties of each line
    for i in range(df.shape[0]):
        group = df.iloc[i]

        
        age = group['lft']
        etnc = group['etngrp']
        gender = group['geslacht']
        education = group['oplniv']
        amount = group['n']
        nodes = []

        # Makes n (the size of the group) nodes of the group
        for j in range(math.ceil((group['n'])/division)):
            id = f'{i}_{j}'
            node = Node(id,age, etnc, education ,gender, amount)
            nodes.append(node)
            G.add_node(node.id)
            all_nodes.append(node)

        # make a dictionary with as key the group properties and value a list of nodes of the group
        group_nodes[f'{age}, {etnc}, {gender}, {education}'] = nodes

        

    return all_nodes, group_nodes

def initialize_edges_probability(df_edges, all_nodes, group_nodes, source = None, destination = None):
    '''
    Initializes the edges of a chosen network (household, family etc.), based on probability
    '''

    # Initializes the source and destinations lists
    source = []
    destination = []

    
    # Loops through all nodes (generated by the initialize node function) and makes links
    for count, node in enumerate(all_nodes):
        
        # Get persons based on the nodes poperties
        person = Person_links(df_edges,node.gender, node.age, node.education, node.etnicity)

        # Get the total amount of links the person group has
        group_links = sum(person.links['n'])

        # Divide the groups link by the amout of nodes so every node gets the same amount of links
        links = group_links/node.amount

        # Update
        if count % 100 == 0:
            print(count/len(all_nodes))

        # Make link based on probability
        prob = person.links['fn']/sum(person.links['fn'])
        
        # Get a list with all the destination groups the current group has
        groups = [f'{age}, {etnc}, {gender}, {education}' for age, etnc, gender, education in zip(person.links['lft_dst'],
        person.links['etngrp_dst'], person.links['geslacht_dst'], person.links['oplniv_dst'])]


        
        # Checks if probability is higher than 0
        if sum(prob) == 0:
            continue

        
        # Get a list (of length links) of destination nodes based on the probability of the link
        destination_nodes = np.random.choice(groups, round(links), p=prob)

        # Loop through the destination nodes and make connection
        for person in destination_nodes:
            
            # Take node id as source
            source.append(node.id)

            # Choose random node from the destination group and make destination node
            try : 
                node2 = np.random.choice(group_nodes[person])
            except:
                print(group_nodes[person])
                print(person)

            destination.append(node2.id)
            
        #     # G.add_edge(node.id, node2.id)
    return source, destination

    


def initialize_edges_links(df_edges, all_nodes, layer ,group_nodes, division, id_source = None, id_destination = None, source = None, destination = None, barabasi = False):     
    '''
    Initializes the links based on the links per group instead of the probability
    '''     

    symetric = False

    if layer == 'huishouden' or layer == 'familie':

        symetric = True
        symetry_dict = {}
        src_groups = []
        dst_groups = []

        for row in df_edges.iterrows():

            row = row[1]
            
            dst_group = f"{row['lft_dst']}, {row['etngrp_dst']}, {row['geslacht_dst']}, {row['oplniv_dst']}"
           
            src_group = f"{row['lft_src']}, {row['etngrp_src']}, {row['geslacht_src']}, {row['oplniv_src']}"

            src_groups.append(src_group)
            dst_groups.append(dst_group)

        df = pd.DataFrame({'src_grps': src_groups, 'dst_grps' : dst_groups})


        for combination in list(product(df['src_grps'], df['dst_grps'])):
            symetry_dict[combination] = 0


    # Divide by the division of (notes ^2)/2 if division > 1
    if division > 1 :
        division = (division**2)/2

    
    # Initializes the source and destinations lists if not multiprocessed
    if source == None and destination == None:
        source = []
        destination = []
        id_source = []
        id_destination = []

    
    # Loops through all connections (generated by the initialize node function) and makes links
    for count, row in enumerate(df_edges.iterrows()):
     
        if count%100 == 0:

            print(count/len(df_edges))
            
        row = row[1]

        # Identifies source and destination group
        src_group = f"{row['lft_src']}, {row['etngrp_src']}, {row['geslacht_src']}, {row['oplniv_src']}"
        dst_group = f"{row['lft_dst']}, {row['etngrp_dst']}, {row['geslacht_dst']}, {row['oplniv_dst']}"

        # Divides the number of edges by the diviser
        connections = round(row['n']/division)
        
        if symetric:
            connections = connections - symetry_dict[(dst_group, src_group)]
     
        # If there are no connections between the source group and the destination group we continue
        if connections == 0:
            continue
        
        # If te data is symetric (familie, household), initiate a dictionary for the destination group

        # Implementing barabasi algorithm
        # if barabasi:

        #     probabilities_groups = {}
        #     edges_group = {}

        #     for group in group_nodes[dst_group]:
        #         group.key = Group(group.key(),group.values(), 1/len(group))
                
        
        for _ in range(connections):
            
            while True:
                

                # if barabasi:
                    

                #     src_node = np.random.choice(group_nodes[src_group])
                    
                #     nodes = np.fromiter(probabilities_group[dst_group].keys(), dtype=float)
                #     nodes_probabilities = np.fromiter(probabilities_group[dst_group].values(), dtype=float)
                
                #     dst_node = np.random.choice(nodes, nodes_probabilities)


                # Take random source node and destination node based on the groups
                src_node = np.random.choice(group_nodes[src_group])
                dst_node = np.random.choice(group_nodes[dst_group])
                
                
                # Checks if the source and destination node are not the same and checks if they aren't already linked
                if dst_node.id != src_node.id and dst_node not in src_node.links:
                    
                    # Checks if data is symetric 
                    if symetric and src_node not in dst_node.links:


                        source.append(str(dst_node))
                        destination.append(str(src_node))
                        src_node.links.append(src_node)
                    
                        id_source.append(dst_node.id)
                        id_destination.append(src_node.id)
                        
                        symetry_dict[(src_group, dst_group)] += 1

                    # Appends both nodes to lists
                    source.append(str(src_node))
                    destination.append(str(dst_node))
                
                    id_source.append(src_node.id)
                    id_destination.append(dst_node.id)

                    src_node.links.append(dst_node)

                    
                    break
            
            
    return source, destination, id_source, id_destination



if __name__ == '__main__':


    '''
    Initialize nodes 
    '''
    G = nx.DiGraph()
    division = 10
    df_nodes = pd.read_csv('Data/tab_n_(with oplniv).csv')
    all_nodes, group_nodes = initialize_nodes(df_nodes, G, division)


    '''
    Initialize edges for multiple layers
    '''

    layers = 'huishouden', 'familie', 'buren', 'werkschool'

    for layer_number, layer in enumerate(layers):
    
        df_edges = pd.read_csv(f'Data/tab_{layer}.csv')
        source, destination, source_id, destination_id = initialize_edges_links(df_edges, all_nodes, layer ,group_nodes, division, id_source = None, id_destination = None, source = None, destination = None, barabasi = False)
        layer_list = list(np.full(len(list(source_id)), layer_number + 1))
        print((layer_list[0]))
        d = {'source_id': list(source_id), 'destination_id':list(destination_id), 'source': list(source), 'destination': list(destination), 'layer': layer_list}

        df_ = pd.DataFrame(d)



        # print('\n')
        # print(pd.Series(destination), pd.Series(destination))
        # df['source'] = source
        # df['destination'] = destination



        df_.to_csv(f'Data/NW_data/{layer}_nw.csv')


    # print(source, destination)


    # manager = mp.Manager()
    # source = manager.list()
    # destination = manager.list()
    # source_id = manager.list()
    # destination_id = manager.list()
    # all_nodes = np.array_split(all_nodes, (mp.cpu_count()//2))

    
    # processes = []    
    # for i in range(mp.cpu_count()//2):
    #     process = mp.Process(target=initialize_edges_links, args=(df_edges, all_nodes[i], layer, group_nodes,division,source_id ,destination_id,source, destination))
    #     processes.append(process)

    # for process in processes:
    #     process.start()

    # for process in processes:
    #     process.join()


    

    


    